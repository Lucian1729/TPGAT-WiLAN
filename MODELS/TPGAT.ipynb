{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-06T10:08:11.655513Z",
          "iopub.status.busy": "2023-07-06T10:08:11.655094Z",
          "iopub.status.idle": "2023-07-06T10:10:02.592058Z",
          "shell.execute_reply": "2023-07-06T10:10:02.590896Z",
          "shell.execute_reply.started": "2023-07-06T10:08:11.655481Z"
        },
        "id": "8vHlenqqcoB8",
        "outputId": "3953bd01-7510-45fd-9156-cca78e41423c",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\n",
            "Collecting torch==1.13.1+cu117\n",
            "  Downloading https://download.pytorch.org/whl/cu117/torch-1.13.1%2Bcu117-cp310-cp310-linux_x86_64.whl (1801.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m710.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.14.1+cu117\n",
            "  Downloading https://download.pytorch.org/whl/cu117/torchvision-0.14.1%2Bcu117-cp310-cp310-linux_x86_64.whl (24.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.13.1\n",
            "  Downloading https://download.pytorch.org/whl/cu117/torchaudio-0.13.1%2Bcu117-cp310-cp310-linux_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1+cu117) (4.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1+cu117) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1+cu117) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1+cu117) (9.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cu117) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cu117) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cu117) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cu117) (3.4)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2+cu118\n",
            "    Uninstalling torchvision-0.15.2+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.2+cu118\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.0.2+cu118\n",
            "    Uninstalling torchaudio-2.0.2+cu118:\n",
            "      Successfully uninstalled torchaudio-2.0.2+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1+cu117 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1+cu117 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.13.1+cu117 torchaudio-0.13.1+cu117 torchvision-0.14.1+cu117\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Kt7GWGi8Xkr",
        "outputId": "157c4e6f-82aa-453b-d977-e0d06bd97ace"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-06T10:10:02.596163Z",
          "iopub.status.busy": "2023-07-06T10:10:02.595858Z",
          "iopub.status.idle": "2023-07-06T10:10:17.089867Z",
          "shell.execute_reply": "2023-07-06T10:10:17.088572Z",
          "shell.execute_reply.started": "2023-07-06T10:10:02.596135Z"
        },
        "id": "iZgyOuL7coCG",
        "outputId": "a32716f4-9325-4416-c349-591a0029c820",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchdata==0.5.1\n",
            "  Downloading torchdata-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.14.1\n",
            "  Downloading torchtext-0.14.1-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.5.1) (1.26.16)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata==0.5.1) (2.27.1)\n",
            "Collecting portalocker>=2.0.0 (from torchdata==0.5.1)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.5.1) (1.13.1+cu117)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.14.1) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.14.1) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->torchdata==0.5.1) (4.7.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.5.1) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.5.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.5.1) (3.4)\n",
            "Installing collected packages: portalocker, torchtext, torchdata\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.15.2\n",
            "    Uninstalling torchtext-0.15.2:\n",
            "      Successfully uninstalled torchtext-0.15.2\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.6.1\n",
            "    Uninstalling torchdata-0.6.1:\n",
            "      Successfully uninstalled torchdata-0.6.1\n",
            "Successfully installed portalocker-2.7.0 torchdata-0.5.1 torchtext-0.14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torchdata==0.5.1 torchtext==0.14.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-06T10:10:17.097502Z",
          "iopub.status.busy": "2023-07-06T10:10:17.095299Z",
          "iopub.status.idle": "2023-07-06T10:10:31.268254Z",
          "shell.execute_reply": "2023-07-06T10:10:31.267128Z",
          "shell.execute_reply.started": "2023-07-06T10:10:17.097463Z"
        },
        "id": "fgIfr5w2coCI",
        "outputId": "091969b9-53c1-447c-9bba-a1cd4fa2a1b7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu117.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu117/torch_scatter-2.1.1%2Bpt113cu117-cp310-cp310-linux_x86_64.whl (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.1+pt113cu117\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.13.1+cu117.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-06T10:10:31.271935Z",
          "iopub.status.busy": "2023-07-06T10:10:31.271551Z",
          "iopub.status.idle": "2023-07-06T10:10:56.721495Z",
          "shell.execute_reply": "2023-07-06T10:10:56.720245Z",
          "shell.execute_reply.started": "2023-07-06T10:10:31.271896Z"
        },
        "id": "JgVl6k43coCK",
        "outputId": "1c4fda26-77a4-40ce-dfb1-a534ff61ecfb",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910460 sha256=58bafe20a9bc80bdd4f034f94dd146a9c637000868f8a960f858a1954e1f765f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-06T10:10:56.724219Z",
          "iopub.status.busy": "2023-07-06T10:10:56.723782Z",
          "iopub.status.idle": "2023-07-06T10:10:59.243881Z",
          "shell.execute_reply": "2023-07-06T10:10:59.242716Z",
          "shell.execute_reply.started": "2023-07-06T10:10:56.724166Z"
        },
        "id": "yN1FByVgcoCL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv,GATv2Conv\n",
        "from torch_scatter import scatter_mean\n",
        "from torch_geometric.data import InMemoryDataset, download_url, extract_zip\n",
        "from torch_geometric.nn import MetaLayer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-06T10:20:24.423030Z",
          "iopub.status.busy": "2023-07-06T10:20:24.422651Z",
          "iopub.status.idle": "2023-07-06T10:20:24.430269Z",
          "shell.execute_reply": "2023-07-06T10:20:24.429163Z",
          "shell.execute_reply.started": "2023-07-06T10:20:24.423000Z"
        },
        "id": "0Pzb-vSNcoCV",
        "outputId": "5cf2a30c-0169-4ce6-beeb-64b95fcfa45b",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available()  else \"cpu\" )\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-06T10:13:51.804937Z",
          "iopub.status.busy": "2023-07-06T10:13:51.804545Z",
          "iopub.status.idle": "2023-07-06T10:13:51.811195Z",
          "shell.execute_reply": "2023-07-06T10:13:51.810142Z",
          "shell.execute_reply.started": "2023-07-06T10:13:51.804907Z"
        },
        "id": "_Pj8h3HecoCW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_int_map(dep):\n",
        "    dep = df.loc[df[\"deployment\"]==dep]\n",
        "    dep = dep.reset_index(drop=True)\n",
        "    return dep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-06T10:10:59.246051Z",
          "iopub.status.busy": "2023-07-06T10:10:59.245394Z",
          "iopub.status.idle": "2023-07-06T10:11:00.452826Z",
          "shell.execute_reply": "2023-07-06T10:11:00.451791Z",
          "shell.execute_reply.started": "2023-07-06T10:10:59.246013Z"
        },
        "id": "R2o8JJX7coCZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"combined_24sce_with_num_AP_STA.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoeYnbkmXIfv",
        "outputId": "54b25505-6cd0-4253-aab4-11a9fd63673b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0.1', 'Unnamed: 0', '0', '1', '2', '3', '4', '5', '6', '7',\n",
              "       '8', '9', '10', '11', 'wlan_code_index', 'x(m)', 'y(m)', 'z(m)',\n",
              "       'primary_channel', 'min_channel_allowed', 'max_channel_allowed',\n",
              "       'node_type', 'rssi', 'sinr', 'air_time_mean', 'channel_bonding_model',\n",
              "       'airtime_0', 'airtime_1', 'airtime_2', 'airtime_3', 'airtime_4',\n",
              "       'airtime_5', 'airtime_6', 'airtime_7', 'deployment', 'throughput',\n",
              "       'central_freq', 'num_AP', 'num_STA'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-Dsjx3FMsA5r"
      },
      "outputs": [],
      "source": [
        "df.drop([\"Unnamed: 0\", \"Unnamed: 0.1\"],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "execution": {
          "iopub.execute_input": "2023-07-06T10:11:00.454755Z",
          "iopub.status.busy": "2023-07-06T10:11:00.454402Z",
          "iopub.status.idle": "2023-07-06T10:11:00.497714Z",
          "shell.execute_reply": "2023-07-06T10:11:00.496795Z",
          "shell.execute_reply.started": "2023-07-06T10:11:00.454723Z"
        },
        "id": "K26GfkcfcoCa",
        "outputId": "f3a38c28-b31f-462c-f5fe-6a5e471c22f4",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-f450ff5c-4eb1-4062-bc0a-33d2e9286d7b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>airtime_3</th>\n",
              "      <th>airtime_4</th>\n",
              "      <th>airtime_5</th>\n",
              "      <th>airtime_6</th>\n",
              "      <th>airtime_7</th>\n",
              "      <th>deployment</th>\n",
              "      <th>throughput</th>\n",
              "      <th>central_freq</th>\n",
              "      <th>num_AP</th>\n",
              "      <th>num_STA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-79.65</td>\n",
              "      <td>-93.86</td>\n",
              "      <td>-109.01</td>\n",
              "      <td>-78.68</td>\n",
              "      <td>-85.3</td>\n",
              "      <td>-98.24</td>\n",
              "      <td>-108.79</td>\n",
              "      <td>-97.21</td>\n",
              "      <td>-103.64</td>\n",
              "      <td>...</td>\n",
              "      <td>50.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>104.96</td>\n",
              "      <td>5.0</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-79.65</td>\n",
              "      <td>-93.86</td>\n",
              "      <td>-109.01</td>\n",
              "      <td>-78.68</td>\n",
              "      <td>-85.3</td>\n",
              "      <td>-98.24</td>\n",
              "      <td>-108.79</td>\n",
              "      <td>-97.21</td>\n",
              "      <td>-103.64</td>\n",
              "      <td>...</td>\n",
              "      <td>50.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.68</td>\n",
              "      <td>5.0</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-79.65</td>\n",
              "      <td>-93.86</td>\n",
              "      <td>-109.01</td>\n",
              "      <td>-78.68</td>\n",
              "      <td>-85.3</td>\n",
              "      <td>-98.24</td>\n",
              "      <td>-108.79</td>\n",
              "      <td>-97.21</td>\n",
              "      <td>-103.64</td>\n",
              "      <td>...</td>\n",
              "      <td>50.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.09</td>\n",
              "      <td>5.0</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-79.65</td>\n",
              "      <td>-93.86</td>\n",
              "      <td>-109.01</td>\n",
              "      <td>-78.68</td>\n",
              "      <td>-85.3</td>\n",
              "      <td>-98.24</td>\n",
              "      <td>-108.79</td>\n",
              "      <td>-97.21</td>\n",
              "      <td>-103.64</td>\n",
              "      <td>...</td>\n",
              "      <td>50.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.51</td>\n",
              "      <td>5.0</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-79.65</td>\n",
              "      <td>-93.86</td>\n",
              "      <td>-109.01</td>\n",
              "      <td>-78.68</td>\n",
              "      <td>-85.3</td>\n",
              "      <td>-98.24</td>\n",
              "      <td>-108.79</td>\n",
              "      <td>-97.21</td>\n",
              "      <td>-103.64</td>\n",
              "      <td>...</td>\n",
              "      <td>50.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.95</td>\n",
              "      <td>5.0</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 37 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f450ff5c-4eb1-4062-bc0a-33d2e9286d7b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-f633875e-6bed-4f46-98b0-d70f632396cd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f633875e-6bed-4f46-98b0-d70f632396cd')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-f633875e-6bed-4f46-98b0-d70f632396cd button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f450ff5c-4eb1-4062-bc0a-33d2e9286d7b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f450ff5c-4eb1-4062-bc0a-33d2e9286d7b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     0      1      2       3      4     5      6       7      8       9  ...  \\\n",
              "0  0.0 -79.65 -93.86 -109.01 -78.68 -85.3 -98.24 -108.79 -97.21 -103.64  ...   \n",
              "1  0.0 -79.65 -93.86 -109.01 -78.68 -85.3 -98.24 -108.79 -97.21 -103.64  ...   \n",
              "2  0.0 -79.65 -93.86 -109.01 -78.68 -85.3 -98.24 -108.79 -97.21 -103.64  ...   \n",
              "3  0.0 -79.65 -93.86 -109.01 -78.68 -85.3 -98.24 -108.79 -97.21 -103.64  ...   \n",
              "4  0.0 -79.65 -93.86 -109.01 -78.68 -85.3 -98.24 -108.79 -97.21 -103.64  ...   \n",
              "\n",
              "   airtime_3  airtime_4  airtime_5  airtime_6  airtime_7  deployment  \\\n",
              "0       50.3        0.0        0.0        0.0        0.0         0.0   \n",
              "1       50.3        0.0        0.0        0.0        0.0         0.0   \n",
              "2       50.3        0.0        0.0        0.0        0.0         0.0   \n",
              "3       50.3        0.0        0.0        0.0        0.0         0.0   \n",
              "4       50.3        0.0        0.0        0.0        0.0         0.0   \n",
              "\n",
              "   throughput  central_freq  num_AP  num_STA  \n",
              "0      104.96           5.0      12       10  \n",
              "1        7.68           5.0      12       10  \n",
              "2       11.09           5.0      12       10  \n",
              "3       14.51           5.0      12       10  \n",
              "4       11.95           5.0      12       10  \n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndx5diS21Fh3",
        "outputId": "665b9e3d-ba1f-4709-9a29-c64eb400b605"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "382840"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZgaLlH7tvCu1"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMO8WSYjUcvf"
      },
      "outputs": [],
      "source": [
        "# test_1 = df[['0', '1', '2', '3', '4', '5', '6', '7','8', '9', '10', '11', 'wlan_code_index', 'x(m)', 'y(m)','z(m)',\n",
        "#             'primary_channel', 'min_channel_allowed', 'max_channel_allowed', 'node_type','rssi',\n",
        "#             'sinr', 'air_time_mean','channel_bonding_model', \"airtime_0\", \"airtime_1\", \"airtime_2\",\n",
        "#               \"airtime_3\", \"airtime_4\", \"airtime_5\", \"airtime_6\", \"airtime_7\",\"central_freq\", 'deployment']]\n",
        "# print(test_1.columns)\n",
        "# test_1.drop([\"deployment\"],axis=1,inplace=True)\n",
        "# print(test_1.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-06T10:28:27.630716Z",
          "iopub.status.busy": "2023-07-06T10:28:27.630364Z",
          "iopub.status.idle": "2023-07-06T10:28:27.648692Z",
          "shell.execute_reply": "2023-07-06T10:28:27.647731Z",
          "shell.execute_reply.started": "2023-07-06T10:28:27.630687Z"
        },
        "id": "-bXLwx5ycoCb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Creating individual graphs\n",
        "# This assumes all APs and STAs are connected to each other\n",
        "def create_graph(split,split_y,deployment):\n",
        "    dep = get_int_map(deployment)\n",
        "    dep_y = dep[\"throughput\"]\n",
        "    dep_x = dep[['0', '1', '2', '3', '4', '5', '6', '7','8', '9', '10', '11','deployment', 'wlan_code_index', 'x(m)', 'y(m)','z(m)',\n",
        "            'primary_channel', 'min_channel_allowed', 'max_channel_allowed', 'node_type','rssi',\n",
        "            'sinr', 'air_time_mean','channel_bonding_model',\"airtime_0\", \"airtime_1\", \"airtime_2\",\n",
        "              \"airtime_3\", \"airtime_4\", \"airtime_5\", \"airtime_6\", \"airtime_7\"]]\n",
        "    #print(dep_x)\n",
        "    dep_reset = dep.reset_index(drop=True)\n",
        "    ap_index = {}\n",
        "    out = dep_reset[dep_reset[\"node_type\"] == 0]\n",
        "    for i in range(len(out)):\n",
        "        ap_index[out.index[i]] = i\n",
        "    #print(ap_index)\n",
        "    node_features = dep_x.iloc[:,13:].values\n",
        "    # print(node_features)\n",
        "    #edge_features = dep.iloc[:,:12].values - here each node has been given an edge feature\n",
        "    # need to give each edge an edge feature\n",
        "    node_targets = dep_y.values\n",
        "    node_features = torch.tensor(node_features, dtype=torch.float)\n",
        "    print(node_features.shape)\n",
        "    #edge_features = torch.tensor(edge_features, dtype=torch.float)\n",
        "    node_targets = torch.tensor(node_targets, dtype=torch.float)\n",
        "    # Add edges here for each deployment\n",
        "    edges = []\n",
        "    edge_features = []\n",
        "    edge_index = []\n",
        "    for i in range(len(dep)):\n",
        "        for j in range(len(dep)):\n",
        "            if (i != j and (dep[\"node_type\"].iloc[i] == 0 and dep[\"node_type\"].iloc[j] == 0)) or (i !=j and (dep[\"node_type\"].iloc[i] == 1 and dep[\"node_type\"].iloc[j] == 0)):\n",
        "                edges.append([i,j])\n",
        "    #print(edges)\n",
        "    edges2=edges\n",
        "    edges = torch.tensor(edges, dtype=torch.float)\n",
        "    #print(\"Edges: \", edges, edges.shape)\n",
        "    # edge_index = torch.tensor(edges, dtype=torch.long)\n",
        "    edge_index = torch.tensor(edges,dtype=torch.long)\n",
        "    edge_index = edge_index.t().contiguous()\n",
        "    #print(edges.detach(), edges.shape)\n",
        "\n",
        "\n",
        "    #tpml station interference\n",
        "    # ap_dist=0\n",
        "    # distance=0\n",
        "\n",
        "    # for j in range(len(out)):\n",
        "    #     for i,val in dep.iterrows():\n",
        "    #         i_pos = np.asarray([dep.at[out.index[j],\"x(m)\"],dep.at[out.index[j],\"y(m)\"],dep.at[out.index[j],\"z(m)\"]])\n",
        "    #         j_pos = np.asarray([dep.at[i,\"x(m)\"],dep.at[i,\"y(m)\"],dep.at[i,\"z(m)\"]])\n",
        "    #         distance = np.linalg.norm(i_pos - j_pos)\n",
        "    #         if val[\"node_type\"]==0:\n",
        "    #             ap_dist=distance\n",
        "    #         else:\n",
        "    #             if ap_dist!=0:\n",
        "    #                 new_int=val[str(j)] + 10*np.log10((ap_dist/distance)**2)\n",
        "    #                 dep.at[i, str(j)]=new_int\n",
        "\n",
        "    print(edges.shape[0])\n",
        "    for i in range(edges.shape[0]):\n",
        "        # print(dep.iloc[int(edges[i][0]), ap_index[int(edges[i][1])]])\n",
        "        i_pos = np.asarray([dep.at[edges2[i][0],\"x(m)\"],dep.at[edges2[i][0],\"y(m)\"],dep.at[edges2[i][0],\"z(m)\"]])\n",
        "        j_pos = np.asarray([dep.at[edges2[i][1],\"x(m)\"],dep.at[edges2[i][1],\"y(m)\"],dep.at[edges2[i][1],\"z(m)\"]])\n",
        "        distance = np.linalg.norm(i_pos - j_pos)\n",
        "        #print(i)\n",
        "        # edge_features.append([distance,dep.iloc[int(edges[i][0]), ap_index[int(edges[i][1])]]])\n",
        "        edge_type = 0\n",
        "        if int(edges2[i][0]) in ap_index.keys():\n",
        "          edge_type = 0\n",
        "        else:\n",
        "          edge_type = 1\n",
        "        edge_features.append([edge_type,distance,dep.at[edges2[i][0],\"rssi\"],dep.iloc[int(edges[i][0]), ap_index[int(edges[i][1])]]])\n",
        "    # edge_features = np.array(edge_features)\n",
        "    # print(edge_features)\n",
        "    edge_features = torch.tensor(edge_features, dtype=torch.float)\n",
        "    #print(edge_features, edge_features.shape)\n",
        "    graph = {\n",
        "        \"edges\": edges,\n",
        "        \"edge_index\": edge_index,\n",
        "        \"node_features\": node_features,\n",
        "        \"edge_features\": edge_features,\n",
        "        \"node_targets\": node_targets\n",
        "    }\n",
        "#     print(\"*\"*10)\n",
        "#     print(edges.shape)\n",
        "#     print(edge_index.shape)\n",
        "#     print(node_features.shape)\n",
        "#     print(edge_features.shape)\n",
        "#     print(node_targets.shape)\n",
        "    return graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-06T10:19:03.496718Z",
          "iopub.status.busy": "2023-07-06T10:19:03.496147Z",
          "iopub.status.idle": "2023-07-06T10:19:05.076427Z",
          "shell.execute_reply": "2023-07-06T10:19:05.075388Z",
          "shell.execute_reply.started": "2023-07-06T10:19:03.496690Z"
        },
        "id": "LFkij5z5coCd",
        "outputId": "538365a4-fd41-42b7-e2b5-9814680f726b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "create_graph(0,0,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJMPpDHYRW63",
        "outputId": "b552ddbe-3d73-457d-c8a7-1be213b30463"
      },
      "outputs": [],
      "source": [
        "create_graph(0,0,0)[\"node_features\"][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-06T10:19:05.079352Z",
          "iopub.status.busy": "2023-07-06T10:19:05.078366Z",
          "iopub.status.idle": "2023-07-06T10:19:05.085230Z",
          "shell.execute_reply": "2023-07-06T10:19:05.083975Z",
          "shell.execute_reply.started": "2023-07-06T10:19:05.079300Z"
        },
        "id": "ZO3ljwu7coCe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def create_geometric_graph(graph):\n",
        "    data = Data(\n",
        "        # Input graph.\n",
        "        x=graph[\"node_features\"],\n",
        "        #pos=pos,\n",
        "        edge_index=graph[\"edge_index\"],\n",
        "        edge_attr=graph[\"edge_features\"],\n",
        "        # Output node targets.\n",
        "        y=graph[\"node_targets\"],\n",
        "        num_nodes = len(graph[\"node_features\"])\n",
        "\n",
        "    )\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-06T10:19:05.087282Z",
          "iopub.status.busy": "2023-07-06T10:19:05.086872Z",
          "iopub.status.idle": "2023-07-06T10:19:06.732846Z",
          "shell.execute_reply": "2023-07-06T10:19:06.731610Z",
          "shell.execute_reply.started": "2023-07-06T10:19:05.087249Z"
        },
        "id": "Kr7yzgfocoCf",
        "outputId": "164c8b53-5259-4da4-e775-bfc21b3a71cb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(create_geometric_graph(create_graph(0,0,0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kORptZ77XIfy",
        "outputId": "a7919f69-c9e4-4e86-aabf-3cea4cdb0365"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "480"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "2400-1920"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "v8mkalUKflgL"
      },
      "outputs": [],
      "source": [
        "# With train, validation and test data.\n",
        "import random\n",
        "import os\n",
        "from torch_geometric.data import InMemoryDataset, download_url, extract_zip\n",
        "# divide into training and testing points\n",
        "class CustomDataset(InMemoryDataset):\n",
        "    def __init__(self, split=\"train\", transform=None):\n",
        "        self.data = pd.read_csv(\"combined_24sce_with_num_AP_STA.csv\")\n",
        "        self.split = split\n",
        "        super(CustomDataset, self).__init__( split, transform)\n",
        "        #self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "        #self.data = pd.read_csv(\"deployment_with_int_map.csv\")\n",
        "        #self.data, self.slices = pd.read_csv(\"deployment_with_int_map.csv\")\n",
        "\n",
        "        # print(\"In init\")\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        # print(\"In raw_file_names\")\n",
        "        return [\"combined_24sce_with_num_AP_STA.csv\"]\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        # print(\"In processed_file_names\")\n",
        "        li = ['data_train_' + str(i) + '.pt' for i in range(1440)]+ ['data_valid_' + str(j) + '.pt' for j in range(1440, 1920)] + ['data_test_' + str(k) + '.pt' for k in range(1920, 2400)]\n",
        "        #print(li)\n",
        "        return ['data_train_' + str(i) + '.pt' for i in range(1440)]+ ['data_valid_' + str(j) + '.pt' for j in range(1440,1920)] + ['data_test_' + str(k) + '.pt' for k in range(1920,2400)]\n",
        "\n",
        "    def _download(self):\n",
        "        '''\n",
        "        print(\"In download\")\n",
        "        path = download_url(self.url, self.raw_dir)\n",
        "        extract_zip(path, self.raw_dir)\n",
        "        # The zip file is removed\n",
        "        os.unlink(path)\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        print(\"In process\")\n",
        "        #df = pd.read_csv(self.raw_paths[0])\n",
        "        X = self.data[['0', '1', '2', '3', '4', '5', '6', '7','8', '9', '10', '11', 'wlan_code_index', 'x(m)', 'y(m)','z(m)',\n",
        "            'primary_channel', 'min_channel_allowed', 'max_channel_allowed', 'node_type','rssi',\n",
        "            'sinr', 'air_time_mean','channel_bonding_model', \"airtime_0\", \"airtime_1\", \"airtime_2\",\n",
        "              \"airtime_3\", \"airtime_4\", \"airtime_5\", \"airtime_6\", \"airtime_7\"]]\n",
        "        y = self.data.loc[:, [\"throughput\", \"deployment\"]]\n",
        "#         X_train = X.iloc[:183854, :]\n",
        "#         X_valid = X.iloc[183854:245139, :]\n",
        "#         X_test = X.iloc[245139:,:]\n",
        "#         print(X_test.columns)\n",
        "#         y_train = y.iloc[:183854, :]\n",
        "#         y_valid = y.iloc[183854:245139, :]\n",
        "#         y_test = y.iloc[245139:,:]\n",
        "        graphs = []\n",
        "        self.l_train=[]\n",
        "        self.l_valid=[]\n",
        "        self.l_test=[]\n",
        "\n",
        "        # print(\"Here\")\n",
        "        for i in range(3, 9):\n",
        "            sce = [i for i in range(320 * (i - 3), 320 * (i - 2))] + [i for i in range(1920 + 80 * (i - 3), 1920 + 80 * (i - 2))]\n",
        "            self.l_train.extend(random.sample(sce, 240))\n",
        "            sce = [x for x in sce if x not in self.l_train]\n",
        "            self.l_valid.extend(random.sample(sce, 80))\n",
        "            sce = [x for x in sce if x not in self.l_valid]\n",
        "            self.l_test.extend(sce)\n",
        "        # l = [i for i in range(1920)]\n",
        "        # self.l_train = random.sample(l, 1440)\n",
        "        # # l = [x for x in l if x not in self.l_train]\n",
        "        # self.l_valid = [1,2,3]\n",
        "        # # l = [x for x in l if x not in self.l_valid]\n",
        "        # self.l_test =random.sample([i for i in range(1920,2400)], 480)\n",
        "        count = 0\n",
        "        if(self.split == \"train\"):\n",
        "\n",
        "            for i in self.l_train:\n",
        "\n",
        "                #X_train = torch.tensor(X_train.to_numpy(), dtype=torch.float)\n",
        "                #y_train = torch.tensor(y_train.to_numpy(), dtype=torch.float)\n",
        "                graph = create_graph(X, y, i)\n",
        "\n",
        "                graph = create_geometric_graph(graph)\n",
        "                graphs.append(graph)\n",
        "\n",
        "                torch.save(graph, os.path.join(self.processed_dir, f'data_train_{count}.pt'))\n",
        "                count += 1\n",
        "        elif(self.split == \"valid\"):\n",
        "            for i in self.l_valid:\n",
        "                #X_test = torch.tensor(X_test.to_numpy(), dtype=torch.float)\n",
        "                #y_test = torch.tensor(y_test.to_numpy(), dtype=torch.float)\n",
        "                graph = create_graph(X, y, i)\n",
        "                graph = create_geometric_graph(graph)\n",
        "                graphs.append(graph)\n",
        "\n",
        "                torch.save(graph, os.path.join(self.processed_dir, f'data_valid_{count}.pt'))\n",
        "                count += 1\n",
        "        else:\n",
        "            for i in self.l_test:\n",
        "                #X_test = torch.tensor(X_test.to_numpy(), dtype=torch.float)\n",
        "                #y_test = torch.tensor(y_test.to_numpy(), dtype=torch.float)\n",
        "                graph = create_graph(X, y, i)\n",
        "                graph = create_geometric_graph(graph)\n",
        "                graphs.append(graph)\n",
        "\n",
        "                torch.save(graph, os.path.join(self.processed_dir, f'data_test_{count}.pt'))\n",
        "                count += 1\n",
        "        #return graphs[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        if(self.split == \"train\"):\n",
        "            #return len(self.processed_file_names[0])\n",
        "            return 1440\n",
        "        elif self.split == \"valid\":\n",
        "            return 480\n",
        "        else:\n",
        "            return 480\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #print(\"Part: \", self.processed_file_names[1])\n",
        "\n",
        "        if(self.split == \"train\"):\n",
        "            data = torch.load(os.path.join(self.processed_dir, f'data_train_{idx}.pt'))\n",
        "        elif(self.split == \"valid\"):\n",
        "            data = torch.load(os.path.join(self.processed_dir, f'data_valid_{idx}.pt'))\n",
        "        elif (self.split==\"test\"):\n",
        "            data = torch.load(os.path.join(self.processed_dir, f'data_test_{idx}.pt'))\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnZO7d9AfqCN",
        "outputId": "f795da60-ab1a-494a-e243-ccd9538fc82c"
      },
      "outputs": [],
      "source": [
        "dataset_train = CustomDataset( split='train')\n",
        "dataset_valid = CustomDataset( split='valid')\n",
        "dataset_test = CustomDataset( split='test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxoZSG8PGyuR"
      },
      "source": [
        "# MODS TO MODEL START HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "3YvaqZlMxQAd"
      },
      "outputs": [],
      "source": [
        "#TPGAT\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_scatter import scatter_mean\n",
        "from torch_geometric.nn import MetaLayer\n",
        "\n",
        "class EdgeModel(torch.nn.Module):\n",
        "    def __init__(self, n_node_features, n_edge_features, hiddens, n_targets):\n",
        "        super().__init__()\n",
        "        self.edge_mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(2 * n_node_features + n_edge_features, hiddens),\n",
        "            torch.nn.LeakyReLU(),\n",
        "            torch.nn.Linear(hiddens, n_targets),\n",
        "        )\n",
        "\n",
        "    def forward(self, src, dest, edge_attr, u=None, batch=None):\n",
        "        #print(\"In edge model\")\n",
        "        #print(src, src.shape)\n",
        "        #print(dest, dest.shape)\n",
        "        #print(edge_attr, edge_attr.shape)\n",
        "        out = torch.cat([src, dest, edge_attr], 1)\n",
        "        out = self.edge_mlp(out)\n",
        "        #out = F.relu(out) ### ADDED THIS ###\n",
        "        #print(\"Exit edge model\")\n",
        "        return out\n",
        "\n",
        "\n",
        "class NodeModel(torch.nn.Module):\n",
        "    def __init__(self, n_node_features, hiddens, n_targets):\n",
        "        super(NodeModel, self).__init__()\n",
        "        self.node_mlp_1 = torch.nn.Sequential(\n",
        "            torch.nn.Linear(n_node_features + hiddens, hiddens),\n",
        "            torch.nn.LeakyReLU(),\n",
        "            torch.nn.Linear(hiddens, hiddens),\n",
        "        )\n",
        "        self.node_mlp_2 = torch.nn.Sequential(\n",
        "            torch.nn.Linear(n_node_features + hiddens, hiddens),\n",
        "            torch.nn.LeakyReLU(),\n",
        "            torch.nn.Linear(hiddens, n_targets),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
        "        #print(\"In node model\")\n",
        "        row, col = edge_index\n",
        "        out = torch.cat([x[col], edge_attr], dim=1)\n",
        "        out = self.node_mlp_1(out)\n",
        "        out = scatter_mean(out, row, dim=0, dim_size=x.size(0))\n",
        "        out = torch.cat([x, out], dim=1)\n",
        "        out = self.node_mlp_2(out)\n",
        "        #print(\"Exit node model\")\n",
        "        return out\n",
        "\n",
        "class MetaNet(torch.nn.Module):\n",
        "    def __init__(self, n_node_features, n_edge_features, num_hidden):\n",
        "        super(MetaNet, self).__init__()\n",
        "\n",
        "        # Input Layer\n",
        "        self.input = MetaLayer(\n",
        "            edge_model=EdgeModel(\n",
        "                n_node_features=n_node_features, n_edge_features=n_edge_features,\n",
        "                hiddens=num_hidden, n_targets=num_hidden),\n",
        "            node_model=NodeModel(n_node_features=n_node_features, hiddens=num_hidden, n_targets=num_hidden)\n",
        "            )\n",
        "\n",
        "        # Output Layer\n",
        "        self.output = MetaLayer(\n",
        "            edge_model=EdgeModel(\n",
        "                n_node_features=num_hidden, n_edge_features=num_hidden,\n",
        "                hiddens=num_hidden, n_targets=num_hidden),\n",
        "            node_model=NodeModel(n_node_features=num_hidden, hiddens=num_hidden, n_targets=1)\n",
        "        )\n",
        "\n",
        "        # Attention Mechanism\n",
        "        self.attention = GATv2Conv(in_channels=num_hidden,out_channels=num_hidden,concat=False,dropout=0.1,negative_slope=0.1,heads=2)\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_attr, y = data.x, data.edge_index, data.edge_attr, data.y\n",
        "        x, edge_attr, _ = self.input(x, edge_index, edge_attr)\n",
        "        x = F.relu(x)\n",
        "        # x = F.dropout(x, p=0.2, training=self.training)\n",
        "\n",
        "        # Attention Mechanism\n",
        "        # x = x.unsqueeze(0)\n",
        "        x = self.attention(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        # x = x.squeeze(0)\n",
        "\n",
        "        x, edge_attr, _ = self.output(x, edge_index, edge_attr)\n",
        "        # x = F.relu(x)\n",
        "        # x = F.dropout(x, p=0.2, training=self.training)\n",
        "        return x.clamp(min=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAnmOvhoG0XI"
      },
      "source": [
        "# MODS TO MODEL END HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-06T10:20:13.786261Z",
          "iopub.status.busy": "2023-07-06T10:20:13.785196Z",
          "iopub.status.idle": "2023-07-06T10:20:13.791675Z",
          "shell.execute_reply": "2023-07-06T10:20:13.790368Z",
          "shell.execute_reply.started": "2023-07-06T10:20:13.786213Z"
        },
        "id": "bPRRP8jlcoCh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "num_node_features = 21\n",
        "num_edge_features = 4\n",
        "num_hidden = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-06T10:20:32.677829Z",
          "iopub.status.busy": "2023-07-06T10:20:32.677457Z",
          "iopub.status.idle": "2023-07-06T10:20:34.309011Z",
          "shell.execute_reply": "2023-07-06T10:20:34.308022Z",
          "shell.execute_reply.started": "2023-07-06T10:20:32.677800Z"
        },
        "id": "u_oMx_LLcoCh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model = MetaNet(num_node_features, num_edge_features, num_hidden).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "G3dzLC61ETfJ"
      },
      "outputs": [],
      "source": [
        "# model  = Net(num_node_features, num_hidden).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2B_GYSk3nZ4",
        "outputId": "c627684d-2d90-49a3-f0c7-078cf2fdffd9"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-06T10:20:46.697896Z",
          "iopub.status.busy": "2023-07-06T10:20:46.697337Z",
          "iopub.status.idle": "2023-07-06T10:20:46.703235Z",
          "shell.execute_reply": "2023-07-06T10:20:46.702092Z",
          "shell.execute_reply.started": "2023-07-06T10:20:46.697865Z"
        },
        "id": "tyIe36JGcoCh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(lr=1e-3,params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-06T10:20:46.966933Z",
          "iopub.status.busy": "2023-07-06T10:20:46.966338Z",
          "iopub.status.idle": "2023-07-06T10:20:46.975716Z",
          "shell.execute_reply": "2023-07-06T10:20:46.974673Z",
          "shell.execute_reply.started": "2023-07-06T10:20:46.966903Z"
        },
        "id": "kOdrIldDcoCi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train(dataset):\n",
        "    # Monitor training.\n",
        "    losses = []\n",
        "\n",
        "    # Put model in training mode!\n",
        "    model.train()\n",
        "    i=0\n",
        "    for i, batch in enumerate(dataset):\n",
        "        #print(\"misaa\")\n",
        "        # Training step.\n",
        "\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch)\n",
        "        loss = torch.sqrt(F.mse_loss(out.squeeze(), batch.y.squeeze()))\n",
        "        #print(f\"Training oss for {i}: {loss}\")\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Monitoring\n",
        "        losses.append(loss.item())\n",
        "        if(i == 1439): break\n",
        "    # Return training metrics.\n",
        "    return losses\n",
        "\n",
        "\n",
        "def evaluate(dataset):\n",
        "    # Monitor evaluation.\n",
        "    losses = []\n",
        "\n",
        "    # Validation (1)\n",
        "    model.eval()\n",
        "    i = 0\n",
        "    for i, batch in enumerate(dataset):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        # Calculate validation losses.\n",
        "        out = model(batch)\n",
        "        loss = torch.sqrt(F.mse_loss(out.squeeze(), batch.y.squeeze()))\n",
        "\n",
        "        # Metric logging.\n",
        "        losses.append(loss.item())\n",
        "        if(i == 479): break\n",
        "\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "jrn8HVXecoCr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "from torch_geometric.data import DataLoader\n",
        "train_loader = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(dataset_valid, batch_size=3, shuffle=True)\n",
        "test_loader = DataLoader(dataset_test, batch_size=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N33mbO96ONBC"
      },
      "outputs": [],
      "source": [
        "# dataset_sce3=[dataset_test[i] for i in range(80)]\n",
        "# dataset_sce4=[dataset_test[i] for i in range(80,160)]\n",
        "# dataset_sce5=[dataset_test[i] for i in range(160,240)]\n",
        "# dataset_sce6=[dataset_test[i] for i in range(240,320)]\n",
        "# dataset_sce7=[dataset_test[i] for i in range(320,400)]\n",
        "# dataset_sce8=[dataset_test[i] for i in range(400,480)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lip8xSKacoCr",
        "outputId": "be1c6e38-ddca-4b99-bbac-c9df1454db21",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for batch in train_loader:\n",
        "    print(batch)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeVD_pAqcoCr",
        "outputId": "3c8502b5-e858-4a07-f12f-7acbce8b2eca",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Metrics recorder per epoch.\n",
        "train_losses = []\n",
        "\n",
        "valid_losses = []\n",
        "valid_losses_corrected = []\n",
        "\n",
        "# Training loop.\n",
        "model.train()\n",
        "\n",
        "for epoch in range(2001):\n",
        "    # Train.\n",
        "    train_epoch_losses = train(train_loader)\n",
        "    print(f\"Epoch: {epoch}, Len of Training loss: {len(train_epoch_losses)}, Average loss: {float(np.sum(train_epoch_losses))/len(train_epoch_losses)}\")\n",
        "    train_losses.append(np.mean(train_epoch_losses))\n",
        "\n",
        "    valid_epoch_losses= evaluate(valid_loader)\n",
        "    print(f\"Len of Validation loss: {len(valid_epoch_losses)}, Average loss: {float(np.sum(valid_epoch_losses))/len(valid_epoch_losses)}\")\n",
        "    valid_losses.append(np.mean(valid_epoch_losses))\n",
        "\n",
        "    if epoch%100==0:\n",
        "        torch.save(model, f\"model_{epoch}.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "7moDq82jwQKL"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "n7mjcXV3coC4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "fmZa5ypccoC5",
        "outputId": "49aac281-8708-496f-f84f-3f17b1f6ea91"
      },
      "outputs": [],
      "source": [
        "num_epochs = 2000\n",
        "\n",
        "plt.plot(np.linspace(1, num_epochs, num_epochs).astype(int), train_losses[:2000], label=\"Training loss\")\n",
        "plt.plot(np.linspace(1, num_epochs, num_epochs).astype(int), valid_losses[:2000], label=\"Testing loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBc4jYvSQ76O"
      },
      "source": [
        "# custom code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "1ArfnkhmQmCL"
      },
      "outputs": [],
      "source": [
        "dataset_sce3=[dataset_test[i] for i in range(80)]\n",
        "dataset_sce4=[dataset_test[i] for i in range(80,160)]\n",
        "dataset_sce5=[dataset_test[i] for i in range(160,240)]\n",
        "dataset_sce6=[dataset_test[i] for i in range(240,320)]\n",
        "dataset_sce7=[dataset_test[i] for i in range(320,400)]\n",
        "dataset_sce8=[dataset_test[i] for i in range(400,480)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "Fo8m0DfBQqLH"
      },
      "outputs": [],
      "source": [
        "sce3_loader = DataLoader(dataset_sce3, batch_size=1, shuffle=True)\n",
        "sce4_loader = DataLoader(dataset_sce4, batch_size=1, shuffle=True)\n",
        "sce5_loader = DataLoader(dataset_sce5, batch_size=1, shuffle=True)\n",
        "sce6_loader = DataLoader(dataset_sce6, batch_size=1, shuffle=True)\n",
        "sce7_loader = DataLoader(dataset_sce7, batch_size=1, shuffle=True)\n",
        "sce8_loader = DataLoader(dataset_sce8, batch_size=1, shuffle=True)\n",
        "test_loader=DataLoader(dataset_test, batch_size=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "8fWFJAoFQuhC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "def find_r2(y_pred, y_true):\n",
        "     metric = r2_score(y_true=y_true, y_pred=y_pred)\n",
        "     return metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "GBRAKvryEXD4"
      },
      "outputs": [],
      "source": [
        "mn = 100\n",
        "prevRmse = 100\n",
        "\n",
        "\n",
        "for i in range(5, 21):\n",
        "  modelv2 = torch.load(f\"/content/model_{i * 100}.pth\")\n",
        "  # modelv2.to(\"cpu\")\n",
        "  modelv2.eval()\n",
        "\n",
        "  def evaluate_test(dataset):\n",
        "      # Monitor evaluation.\n",
        "      deployment_rmses=[]\n",
        "      deployment_maes=[]\n",
        "      #deployment_r2s=[]\n",
        "      # y_t_list=[]\n",
        "      # y_p_list=[]\n",
        "      # Validation (1)\n",
        "      modelv2.eval()\n",
        "      i = 0\n",
        "      for i, batch in enumerate(dataset):\n",
        "          batch = batch.to(device)\n",
        "\n",
        "          # Calculate validation losses.\n",
        "          out = modelv2(batch)\n",
        "          deployment_rmse = torch.sqrt(F.mse_loss(out.squeeze(), batch.y.squeeze()))\n",
        "          deployment_mae=np.mean(np.sqrt(torch.pow(out.view(-1) - batch.y.view(-1), 2).tolist()))\n",
        "          #deployment_r2= find_r2(out.view(-1), batch.y.view(-1))\n",
        "          # Metric logging.\n",
        "          deployment_rmses.append(deployment_rmse.item())\n",
        "          deployment_maes.append(deployment_mae)\n",
        "          # y_t_list.extend(out.view(-1).tolist())\n",
        "          # y_p_list.extend(batch.y.view(-1).tolist())\n",
        "          #deployment_r2s.append(deployment_r2)\n",
        "          if(i == 479): break\n",
        "      avg_rmse=np.mean(deployment_rmses)\n",
        "      mae=np.mean(deployment_maes)\n",
        "      r2=0.0 #find_r2(y_t_list,y_p_list)\n",
        "      return avg_rmse, mae, r2\n",
        "\n",
        "  full_test_rmse, full_test_mae, full_test_r2= evaluate_test(test_loader)\n",
        "  if(full_test_rmse < prevRmse):\n",
        "    prevRmse = full_test_rmse\n",
        "    mn = i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5RRk4kcEZPV",
        "outputId": "af05ec00-2f04-4974-f3e2-afb58923d7d4"
      },
      "outputs": [],
      "source": [
        "print(mn)\n",
        "print(prevRmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "V4ELBoa2Rwaf"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy1xuS5ZcoC8",
        "outputId": "3de28111-f725-4e04-ce8b-aa3ac1d92559"
      },
      "outputs": [],
      "source": [
        "modelv2 = torch.load(\"model_2000.pth\")\n",
        "# modelv2.to(\"cpu\")\n",
        "modelv2.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "ZwbyGOHpSgxo"
      },
      "outputs": [],
      "source": [
        "def evaluate_test(dataset):\n",
        "    # Monitor evaluation.\n",
        "    deployment_rmses=[]\n",
        "    deployment_maes=[]\n",
        "    #deployment_r2s=[]\n",
        "    # y_t_list=[]\n",
        "    # y_p_list=[]\n",
        "    # Validation (1)\n",
        "    modelv2.eval()\n",
        "    i = 0\n",
        "    for i, batch in enumerate(dataset):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        # Calculate validation losses.\n",
        "        out = modelv2(batch)\n",
        "        deployment_rmse = torch.sqrt(F.mse_loss(out.squeeze(), batch.y.squeeze()))\n",
        "        deployment_mae=np.mean(np.sqrt(torch.pow(out.view(-1) - batch.y.view(-1), 2).tolist()))\n",
        "        #deployment_r2= find_r2(out.view(-1), batch.y.view(-1))\n",
        "        # Metric logging.\n",
        "        deployment_rmses.append(deployment_rmse.item())\n",
        "        deployment_maes.append(deployment_mae)\n",
        "        # y_t_list.extend(out.view(-1).tolist())\n",
        "        # y_p_list.extend(batch.y.view(-1).tolist())\n",
        "        #deployment_r2s.append(deployment_r2)\n",
        "        if(i == 479): break\n",
        "    avg_rmse=np.mean(deployment_rmses)\n",
        "    mae=np.mean(deployment_maes)\n",
        "    r2=0\n",
        "    return avg_rmse, mae, r2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "4IEcBjRGONBa"
      },
      "outputs": [],
      "source": [
        "dataset_sce3=[dataset_test[i] for i in range(80)]\n",
        "dataset_sce4=[dataset_test[i] for i in range(80,160)]\n",
        "dataset_sce5=[dataset_test[i] for i in range(160,240)]\n",
        "dataset_sce6=[dataset_test[i] for i in range(240,320)]\n",
        "dataset_sce7=[dataset_test[i] for i in range(320,400)]\n",
        "dataset_sce8=[dataset_test[i] for i in range(400,480)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "r94JrVvRONBa"
      },
      "outputs": [],
      "source": [
        "sce3_loader = DataLoader(dataset_sce3, batch_size=1, shuffle=True)\n",
        "sce4_loader = DataLoader(dataset_sce4, batch_size=1, shuffle=True)\n",
        "sce5_loader = DataLoader(dataset_sce5, batch_size=1, shuffle=True)\n",
        "sce6_loader = DataLoader(dataset_sce6, batch_size=1, shuffle=True)\n",
        "sce7_loader = DataLoader(dataset_sce7, batch_size=1, shuffle=True)\n",
        "sce8_loader = DataLoader(dataset_sce8, batch_size=1, shuffle=True)\n",
        "test_loader=DataLoader(dataset_test, batch_size=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMwk5tkAhNLB"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(dataset_test, batch_size=1, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "S3JS5k_jcoC8"
      },
      "outputs": [],
      "source": [
        "#evaluate the model on the test set and for separate scenarios\n",
        "full_test_rmse, full_test_mae, full_test_r2= evaluate_test(test_loader)\n",
        "# Scenario 3 evaluation\n",
        "sce3_rmse, sce3_mae, sce3_r2 = evaluate_test(sce3_loader)\n",
        "\n",
        "# Scenario 4 evaluation\n",
        "sce4_rmse, sce4_mae, sce4_r2 = evaluate_test(sce4_loader)\n",
        "\n",
        "# Scenario 5 evaluation\n",
        "sce5_rmse, sce5_mae, sce5_r2 = evaluate_test(sce5_loader)\n",
        "\n",
        "# Scenario 6 evaluation\n",
        "sce6_rmse, sce6_mae, sce6_r2 = evaluate_test(sce6_loader)\n",
        "\n",
        "# Scenario 7 evaluation\n",
        "sce7_rmse, sce7_mae, sce7_r2 = evaluate_test(sce7_loader)\n",
        "\n",
        "# Scenario 8 evaluation\n",
        "sce8_rmse, sce8_mae, sce8_r2 = evaluate_test(sce8_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSUqSWz-ONBb",
        "outputId": "eacd861b-8935-4b2a-c1e5-ed616c6dc523"
      },
      "outputs": [],
      "source": [
        "print(\"Scenario  | Avg. RMSE  | MAE        | R^2\")\n",
        "print(\"-------------------------------------------------\")\n",
        "print(f\"Full Test | {full_test_rmse:.4f} | {full_test_mae:.4f} | {full_test_r2:.4f}\")\n",
        "print(f\"Scenario 3| {sce3_rmse:.4f} | {sce3_mae:.4f} | {sce3_r2:.4f}\")\n",
        "print(f\"Scenario 4| {sce4_rmse:.4f} | {sce4_mae:.4f} | {sce4_r2:.4f}\")\n",
        "print(f\"Scenario 5| {sce5_rmse:.4f} | {sce5_mae:.4f} | {sce5_r2:.4f}\")\n",
        "print(f\"Scenario 6| {sce6_rmse:.4f} | {sce6_mae:.4f} | {sce6_r2:.4f}\")\n",
        "print(f\"Scenario 7| {sce7_rmse:.4f} | {sce7_mae:.4f} | {sce7_r2:.4f}\")\n",
        "print(f\"Scenario 8| {sce8_rmse:.4f} | {sce8_mae:.4f} | {sce8_r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
